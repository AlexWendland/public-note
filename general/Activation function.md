---
aliases:
  - activation function
checked: false
created: 2024-01-20
last_edited: 2024-01-20
draft: false
tags:
  - machine-learning
type: definition
---
>[!tldr] Activation function
>An *activation function* $a: \mathbb{R} \rightarrow \mathbb{R}$ gets applied in a [[Perceptron (neural network)|perceptron]] after the weighted sum of the inputs. It is the non-linear term. Classic activation functions are
>- Identity function, 
>- [[Binary step]],
>- [[Sigmoid function]],
>- [[Rectified linear unit (ReLU)]], or
>- [[Hyperbolic tangent (tanh)]].
