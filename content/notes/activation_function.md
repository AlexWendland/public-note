---
aliases:
  - activation function
created: 2024-01-20
date_checked:
draft: false
last_edited: 2026-02-05
tags:
  - machine-learning
title: Activation function
type: definition
---
>[!definition] Activation function
>An *activation function* $a: \mathbb{R} \rightarrow \mathbb{R}$ gets applied in a [perceptron](perceptron_(neural_network).md) after the weighted sum of the inputs. It is the non-linear term. Classic activation functions are
>- Identity function,
>- [Binary step](binary_step.md),
>- [Sigmoid function](sigmoid_function.md),
>- [Rectified linear unit (ReLU)](rectified_linear_unit_(relu).md), or
>- [Hyperbolic tangent (tanh)](hyperbolic_tangent_(tanh).md).
